{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZHLQXLjLkgbWdid3xGJB2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syahmins/ImageClassification/blob/main/RockScissorPaper_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TaF866fcXM_F"
      },
      "outputs": [],
      "source": [
        "# submission for Dicoding\n",
        "# profile: https://www.dicoding.com/users/syahmin\n",
        "# name: syahmin sukhairi\n",
        "# email: syahminsukhairi@gmail.com\n",
        "\n",
        "#import all module\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import shutil\n",
        "import splitfolders\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split_folders tqdm"
      ],
      "metadata": {
        "id": "md2YtTHyYFTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data training location\n",
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "metadata": {
        "id": "PkdeX_nOYeZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare temp image location\n",
        "import zipfile, os\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "XCBIsi8kY9vZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images/'\n",
        "if ('data_model' in os.listdir(base_dir)):\n",
        "  shutil.rmtree(os.path.join(base_dir, 'data_model'))\n",
        "\n",
        "\"\"\"\n",
        "splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images/',\n",
        "                    output ='/tmp/rockpaperscissors/rps-cv-images/data_model',\n",
        "                    seed=None, ratio=(.8,.2))\n",
        "\n",
        "\n",
        "# Put all files into the correct folders\n",
        "# ROCK\n",
        "rock_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/rock')\n",
        "train_rock_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/data_model/train/rock')\n",
        "val_rock_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/data_model/val/rock')\n",
        "\n",
        "# PAPER\n",
        "paper_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/paper')\n",
        "train_paper_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/data_model/train/paper')\n",
        "val_paper_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/data_model/val/paper')\n",
        "\n",
        "# SCISSORS\n",
        "scissors_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/scissors')\n",
        "train_scissors_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/data_model/train/scissors')\n",
        "val_scissors_dir = os.path.join('/tmp/rockpaperscissors/rps-cv-images/data_model/val/scissors')\n",
        "\"\"\"\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
        "\n",
        "train_dataset = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='full_dataset',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=(280, 280),\n",
        "                                                 subset=\"training\",\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "validation_dataset = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='full_dataset',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=(280, 280),\n",
        "                                                 subset=\"validation\",\n",
        "                                                 class_mode='categorical')"
      ],
      "metadata": {
        "id": "FN-Jt0uMDc5i",
        "outputId": "748904cd-723b-481c-be3a-89d8f4ef8c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8a775d69f07a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mimage_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m train_dataset = image_generator.flow_from_directory(batch_size=32,\n\u001b[0m\u001b[1;32m     31\u001b[0m                                                  \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'full_dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                  \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \"\"\"\n\u001b[0;32m-> 1649\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1650\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'full_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = 'dataset_raw'\n",
        "dataset_dir = os.path.join(dataset_dir, '/tmp/rockpaperscissors/rps-cv-images/')\n",
        "classdir_list = ['paper', 'rock', 'scissors']\n",
        "training_percentage = 0.9\n",
        "\n",
        "training_dataset_dir = 'training'\n",
        "validation_dataset_dir = 'validation'\n",
        "\n",
        "# os.mkdir(training_dataset_dir)\n",
        "# os.mkdir(validation_dataset_dir)"
      ],
      "metadata": {
        "id": "nYctgN7P4o1Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "rock_files = os.listdir(rock_dir)\n",
        "paper_files = os.listdir(paper_dir)\n",
        "scissors_files = os.listdir(scissors_dir)\n",
        "\n",
        "pic_index = 2\n",
        "\n",
        "next_rock = [os.path.join(rock_dir, fname)\n",
        "                for fname in rock_files[pic_index-2:pic_index]]\n",
        "next_paper = [os.path.join(paper_dir, fname)\n",
        "                for fname in paper_files[pic_index-2:pic_index]]\n",
        "next_scissors = [os.path.join(scissors_dir, fname)\n",
        "                for fname in scissors_files[pic_index-2:pic_index]]"
      ],
      "metadata": {
        "id": "_R1IcwFUZSbc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.preprocessing\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "training_dir = \"/tmp/rockpaperscissors/rps-cv-images/data_model/train\"\n",
        "\n",
        "training_datagen = tf.keras.preprocessing.image.ImageDataGenerator (\n",
        "    rescale = 1./255,\n",
        "    zoom_range = 0.25,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        ")\n",
        "\n",
        "validation_dir = \"/tmp/rockpaperscissors/rps-cv-images/data_model/val\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\ttraining_dir,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tvalidation_dir,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical'\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(8, (3, 3), input_shape = (150, 150, 3), activation ='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation ='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation ='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=28, steps_per_epoch=14,\n",
        "    validation_data = validation_generator,\n",
        "    verbose = 1,\n",
        "    validation_steps=3)\n",
        "\n",
        "model.save(\"rockpaperscissors.h5\")"
      ],
      "metadata": {
        "id": "MYf5b42OZXe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload picture and prediction result\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  # urutan cLass: Paper, Rock, Scissors\n",
        "\n",
        "  if classes[0][0]==1:\n",
        "    print('your picture is: paper')\n",
        "  elif classes[0][1]==1:\n",
        "    print('your picture is: rock')\n",
        "  elif classes[0][2]==1:\n",
        "    print('your picture is: scissors')\n",
        "  else:\n",
        "    print('your picture is: unknown')"
      ],
      "metadata": {
        "id": "TzvnpLlkvG9h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}